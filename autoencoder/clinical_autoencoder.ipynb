{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clinical_autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hah7xMSJW3L7",
        "colab_type": "text"
      },
      "source": [
        "# **Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrG0KzYzU83w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#python functionalities\n",
        "import os\n",
        "import pickle\n",
        "import pandas\n",
        "import numpy as np\n",
        "\n",
        "#display results\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "#T-SNE\n",
        "import cv2\n",
        "from sklearn import manifold\n",
        "\n",
        "#one-hot-encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#model functionalities\n",
        "import tensorflow as tf\n",
        "from keras import regularizers\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Conv2D, Conv2DTranspose, BatchNormalization, Reshape, Flatten, Dense, Dropout, Concatenate, Activation\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#classification\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKUjwIA8-joQ",
        "colab_type": "text"
      },
      "source": [
        "# **Import the NCIA dataset from Google Drive.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XUa4fDs2U3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_MCGILL = '/content/drive/My Drive/Bachelor Thesis/Model-Data/128/MCGILL'\n",
        "dir_MAASTRO = '/content/drive/My Drive/Bachelor Thesis/Model-Data/128/MAASTRO'\n",
        "\n",
        "# read the training data\n",
        "with open(dir_MCGILL + '/train_data.pxl', 'rb') as f:\n",
        "  train_data = np.array(pickle.load(f))\n",
        "with open(dir_MCGILL + '/train_label.pxl', 'rb') as f:\n",
        "  train_label = np.array(pickle.load(f))\n",
        "with open(dir_MCGILL + '/train_contour.pxl', 'rb') as f:\n",
        "  train_contour = np.array(pickle.load(f))\n",
        "with open(dir_MCGILL + '/train_clinical.pxl', 'rb') as f:\n",
        "  train_clinical = np.array(pickle.load(f))\n",
        "\n",
        "# read the testing data\n",
        "with open(dir_MCGILL + '/test_data.pxl', 'rb') as f:\n",
        "  test_data = np.array(pickle.load(f))\n",
        "with open(dir_MCGILL + '/test_label.pxl', 'rb') as f:\n",
        "  test_label = np.array(pickle.load(f))\n",
        "with open(dir_MCGILL + '/test_contour.pxl', 'rb') as f:\n",
        "  test_contour = np.array(pickle.load(f))\n",
        "with open(dir_MCGILL + '/test_clinical.pxl', 'rb') as f:\n",
        "  test_clinical = np.array(pickle.load(f))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrC0wFwRt3z8",
        "colab_type": "text"
      },
      "source": [
        "# **Prepare the data.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQRDwgfHzF4O",
        "colab_type": "text"
      },
      "source": [
        "## Radiomic Data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSXzmJ0Fui2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#separate labels according to the metastasis type\n",
        "def vectorize_labels(labels):\n",
        "  local, distant, death = [], [], []\n",
        "\n",
        "  for metastasis in labels:\n",
        "    local.append(metastasis[0])\n",
        "    distant.append(metastasis[1])\n",
        "    death.append(metastasis[2])\n",
        "\n",
        "  return np.asarray(local).astype('float32'), np.asarray(distant).astype('float32'), np.asarray(death).astype('float32')\n",
        "\n",
        "#normalize the data\n",
        "train_x = train_data.astype('float32') / 2000.\n",
        "test_x = test_data.astype('float32') / 2000.\n",
        "\n",
        "#reshape the data\n",
        "train_x = np.reshape(train_x, (len(train_x), 128, 128, 1))\n",
        "test_x  = np.reshape(test_x, (len(test_x), 128, 128, 1))\n",
        "\n",
        "#vectorize the labels\n",
        "train_local, train_distant, train_death = vectorize_labels(train_label)\n",
        "test_local, test_distant, test_death = vectorize_labels(test_label)\n",
        "train_y = np.asarray(train_label).astype('float32')\n",
        "test_y = np.asarray(test_label).astype('float32')\n",
        "\n",
        "#display data shape\n",
        "print(\"Input data shape\", train_x.shape)\n",
        "print(\"Input label shape\", train_y.shape)\n",
        "print(\"Clinical data shape\", train_clinical.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_BMj40MzJce",
        "colab_type": "text"
      },
      "source": [
        "## Clinical Data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzPKfWJzzLJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiColumnLabelEncoder:\n",
        "    def __init__(self, columns = None):\n",
        "        self.columns = columns # list of column to encode    \n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "      return self    \n",
        "        \n",
        "    def transform(self, X):\n",
        "      \"\"\"\n",
        "      Transforms columns of X specified in self.columns using LabelEncoder(). \n",
        "      If no columns specified, transforms all columns in X.\n",
        "      \"\"\"\n",
        "      output = X.copy()\n",
        "\n",
        "      if self.columns is not None:\n",
        "          for col in self.columns:\n",
        "              output[col] = LabelEncoder().fit_transform(output[col])\n",
        "      else:\n",
        "          for colname, col in output.iteritems():\n",
        "              output[colname] = LabelEncoder().fit_transform(col)\n",
        "\n",
        "      return output    \n",
        "      \n",
        "    def fit_transform(self, X, y=None):\n",
        "      return self.fit(X, y).transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v58JvyZF9O8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_encoder   = MultiColumnLabelEncoder()\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "bins = [0, 20, 30, 40, 50, 60, 70, 80, 120]\n",
        "labels = ['0-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80+']\n",
        "\n",
        "def one_hot_encoding(data):\n",
        "  df = pandas.DataFrame({'age': data[:, 0],\n",
        "                         'location': data[:, 1],\n",
        "                         't-stage': data[:, 2],\n",
        "                         'n-stage': data[:, 3]})\n",
        "  \n",
        "  df.age = df.age.astype('float')\n",
        "  df.age = pandas.cut(df.age, bins, labels=labels, include_lowest = True)\n",
        "\n",
        "  le  = label_encoder.fit_transform(df)\n",
        "  ohe = one_hot_encoder.fit_transform(le)\n",
        "  \n",
        "  return ohe\n",
        "\n",
        "for tmp in bins:\n",
        "  train_clinical = np.append(train_clinical, [[str(tmp), 'Oropharynx', 'T1', 'NO']], axis=0)\n",
        "  test_clinical  = np.append(test_clinical, [[str(tmp), 'Oropharynx', 'T1', 'NO']], axis=0)\n",
        "\n",
        "train_ohe = one_hot_encoding(train_clinical)\n",
        "test_ohe  = one_hot_encoding(test_clinical)\n",
        "\n",
        "n = len(bins)\n",
        "train_ohe = train_ohe[:-n, :]\n",
        "test_ohe  = test_ohe[:-n, :]\n",
        "train_clinical = train_clinical[:-n, :]\n",
        "test_clinical  = test_clinical[:-n, :]\n",
        "\n",
        "print(\"Clinical data one-hot encoding shape\", train_ohe.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaBR-zMju3MV",
        "colab_type": "text"
      },
      "source": [
        "# **Build convolutional autoencoder.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs2ro2aprpE7",
        "colab_type": "text"
      },
      "source": [
        "## Encoder and Decoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7Z3mFxJ8BAc",
        "colab_type": "text"
      },
      "source": [
        "Encoder and Decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trNfnfeUrral",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_conv2d(layer, filters, stride, name):\n",
        "  layer = Conv2D(filters, kernel_size=(3,3), strides=stride, activation='relu', padding='same', name=('encoder_conv_%s' % name))(layer)\n",
        "  layer = BatchNormalization(name=('encoder_bn_%s' % name))(layer)\n",
        "\n",
        "  return layer\n",
        "\n",
        "def custom_conv2d_transpose(layer, filters, stride, name):\n",
        "  layer = Conv2DTranspose(filters, kernel_size=(3,3), strides=stride, activation='relu', padding='same', name=('decoder_conv_%s' % name))(layer)\n",
        "  layer = BatchNormalization(name=('decoder_bn_%s' % name))(layer)\n",
        "\n",
        "  return layer\n",
        "\n",
        "def build_encoder_layers(layer, filters_per_layer):\n",
        "  for i, filters in enumerate(filters_per_layer):\n",
        "    layer = custom_conv2d(layer, filters, (1, 1), '1-1_%d' % i)\n",
        "    layer = custom_conv2d(layer, filters, (1, 1), '1-2_%d' % i)\n",
        "    layer = custom_conv2d(layer, filters, (2, 2), '2-1_%d' % i)\n",
        "\n",
        "  return layer\n",
        "\n",
        "def build_decoder_layers(layer, filters_per_layer):\n",
        "  for i, filters in enumerate(filters_per_layer[::-1]):\n",
        "    layer = custom_conv2d_transpose(layer, filters, (2, 2), '2-1_%d' % i)\n",
        "    layer = custom_conv2d_transpose(layer, filters, (1, 1), '1-2_%d' % i)\n",
        "    layer = custom_conv2d_transpose(layer, filters, (1, 1), '1-1_%d' % i)\n",
        "\n",
        "  output = Conv2D(1, (3, 3), activation='sigmoid', padding='same', name=('decoder_conv_output'))(layer)\n",
        "\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHXK8Mtf-syQ",
        "colab_type": "text"
      },
      "source": [
        "Build Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhzCFUaP-uRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded = build_encoder_layers(input_img, nb_filters)\n",
        "decoded = build_decoder_layers(encoded, nb_filters)\n",
        "\n",
        "ae = Model(input_img, decoded)\n",
        "ae.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
        "ae.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I1DVqasQ0Es",
        "colab_type": "text"
      },
      "source": [
        "## Autoencoder Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIZPNxCkToW4",
        "colab_type": "text"
      },
      "source": [
        "Learning parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7yNjlyIRMmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hyper-parameters\n",
        "epochs_AE = 300\n",
        "epochs_FULL = 150\n",
        "batch_size = 64\n",
        "input_img  = Input(shape=(128, 128, 1))\n",
        "nb_filters = (32, 64, 128)\n",
        "\n",
        "#model layers\n",
        "l = 18"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP7yVWLbrE0p",
        "colab_type": "text"
      },
      "source": [
        "Define the fully connected layers that will be stacked up with the encoder function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsFTR8aOM14b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def m_encoder(enco):\n",
        "  flat = Flatten()(enco)\n",
        "  drop = Dropout(0.25)(flat)\n",
        "  den1 = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001))(drop)\n",
        "  drop = Dropout(0.5)(den1)\n",
        "  out  = Dense(1, activation='sigmoid')(drop)\n",
        "  \n",
        "  return out\n",
        "\n",
        "def m_sequential(input):\n",
        "  seq = Sequential()\n",
        "  seq.add(Dense(16, activation='relu', input_shape=(input,)))\n",
        "  seq.add(Dropout(0.5))\n",
        "  seq.add(Dense(16, activation='relu'))\n",
        "  seq.add(Dropout(0.5))\n",
        "\n",
        "  return seq\n",
        "\n",
        "#create augmented image generator\n",
        "datagen = ImageDataGenerator(rotation_range=45,\n",
        "                             width_shift_range=0.2,\n",
        "                             height_shift_range=0.2,\n",
        "                             shear_range=0.2,\n",
        "                             zoom_range=0.2,\n",
        "                             horizontal_flip=True,\n",
        "                             fill_mode='nearest')\n",
        "\n",
        "#compute quantities required for featurewise normalization\n",
        "datagen.fit(train_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J_uexCoaOh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cf = tf.keras.models.load_model('/content/drive/My Drive/Bachelor Thesis/autoencoder_300_128_full.h5')\n",
        "\n",
        "def create_model():\n",
        "  #create the radiomic and clinical data models\n",
        "  cnn = Model(input_img, m_encoder(build_encoder_layers(input_img, nb_filters)))\n",
        "  seq = m_sequential(train_ohe.shape[1])\n",
        "\n",
        "  #merge models\n",
        "  merged = Concatenate()([seq.output, cnn.output])\n",
        "  output = Dense(1, input_dim=2, activation='sigmoid', use_bias=True)(merged)\n",
        "  full_model = Model(inputs=[seq.input, cnn.input], outputs=output)\n",
        "\n",
        "  #set layer weights of the autoencoder\n",
        "  for l1, l2 in zip(full_model.layers[:l], model_cf.layers[:l]):\n",
        "    l1.set_weights(l2.get_weights())\n",
        "    l1.trainable = False\n",
        "\n",
        "  #compile the model\n",
        "  full_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "  return full_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTr30-6bara5",
        "colab_type": "text"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO_GlejuPX31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "tmp_model = create_model()\n",
        "tmp_model.fit([train_ohe, train_x], train_death, batch_size=64, epochs=100, verbose=0,validation_data=([test_ohe, test_x], test_death))\n",
        "pred = tmp_model.predict([test_ohe, test_x])\n",
        "fpr, tpr, _ = roc_curve(test_death, pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "print(roc_auc)\n",
        "\n",
        "DM_fpr = fpr\n",
        "DM_tpr = tpr\n",
        "DM_auc = roc_auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbDF0x3K903A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clinical = m_sequential(train_ohe.shape[1])\n",
        "clinical.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "clinical.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "clinical.fit(train_ohe, train_local, batch_size=256, epochs=100, verbose=0, validation_data=(test_ohe, test_local))\n",
        "\n",
        "pred = clinical.predict(test_ohe)\n",
        "fpr, tpr, _ = roc_curve(test_local, pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "LR_fpr = fpr\n",
        "LR_tpr = tpr\n",
        "LR_auc = roc_auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR722CqECMrg",
        "colab_type": "text"
      },
      "source": [
        "# **Binary Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkaA5pMHdFwd",
        "colab_type": "text"
      },
      "source": [
        "## ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdbiGKUGdIrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(8,6))\n",
        "\n",
        "plt.figure()\n",
        "#plt.plot(LR_fpr, LR_tpr, 'blue', label='Local recurrence, AUC={:.2f}'.format(LR_auc))\n",
        "#plt.plot(DM_fpr, DM_tpr, 'green', label='Distant metastasis, AUC={:.2f}'.format(DM_auc))\n",
        "plt.plot(OS_fpr, OS_tpr, 'red', label='Death, AUC={:.2f}'.format(OS_auc))\n",
        "    \n",
        "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
        "\n",
        "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.xlabel(\"Flase Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
        "plt.legend(prop={'size':13}, loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXozcV7UwG74",
        "colab_type": "text"
      },
      "source": [
        "# **Display Encoding.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "453vH9aDs637",
        "colab_type": "text"
      },
      "source": [
        "Autoencoder image input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2Gh4ff_s8ma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(30, 15))\n",
        "\n",
        "\n",
        "for i in range(32):\n",
        "  sub = fig.add_subplot(4, 8, i+1)\n",
        "  sub.imshow(train_x[i].reshape(160, 160))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3rNkmND6prj",
        "colab_type": "text"
      },
      "source": [
        "Autoencoder image reconstruction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_2zuMSdwKHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder_rec = tf.keras.models.load_model('/content/drive/My Drive/Bachelor Thesis/autoencoder_300_clinical_datagen.h5')\n",
        "\n",
        "decoded_imgs = autoencoder_rec.predict(test_x)\n",
        "\n",
        "# number of scans to display\n",
        "scans = 8\n",
        "\n",
        "plt.figure(figsize=(30, 8))\n",
        "for i in range(scans):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, scans, i + 1)\n",
        "    plt.imshow(test_x[i].reshape(160, 160), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, scans, i + scans + 1)\n",
        "    plt.imshow(decoded_imgs[i].reshape(160, 160), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izdK4j3A6ubh",
        "colab_type": "text"
      },
      "source": [
        "Autoencoder loss progression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfSxal3K6xgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "\n",
        "epochs = range(epochs)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}