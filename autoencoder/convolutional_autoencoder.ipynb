{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional_autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hah7xMSJW3L7",
        "colab_type": "text"
      },
      "source": [
        "# **Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrG0KzYzU83w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#python functionalities\n",
        "import os\n",
        "import pickle\n",
        "import pandas\n",
        "import numpy as np\n",
        "\n",
        "#display results\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "#T-SNE\n",
        "import cv2\n",
        "from sklearn import manifold\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "\n",
        "#model functionalities\n",
        "import tensorflow as tf\n",
        "from keras import regularizers\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, BatchNormalization, Reshape, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#classification\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKUjwIA8-joQ",
        "colab_type": "text"
      },
      "source": [
        "# **Import the NCIA dataset from Google Drive.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XUa4fDs2U3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_MCGILL = '/content/drive/My Drive/Bachelor Thesis/Model-Data/128/MCGILL'\n",
        "dir_MAASTRO = '/content/drive/My Drive/Bachelor Thesis/Model-Data/128/MAASTRO'\n",
        "\n",
        "# read the training data\n",
        "with open(dir_MCGILL + '/train_data.pxl', 'rb') as f:\n",
        "  train_data = np.array(pickle.load(f))\n",
        "with open(dir_MCGILL + '/train_label.pxl', 'rb') as f:\n",
        "  train_label = np.array(pickle.load(f))\n",
        "with open(dir_MCGILL + '/train_contour.pxl', 'rb') as f:\n",
        "  train_contour = np.array(pickle.load(f))\n",
        "\n",
        "# read the testing data\n",
        "with open(dir_MCGILL + '/test_data.pxl', 'rb') as f:\n",
        "  test_data = np.array(pickle.load(f))\n",
        "with open(dir_MCGILL + '/test_label.pxl', 'rb') as f:\n",
        "  test_label = np.array(pickle.load(f))\n",
        "with open(dir_MCGILL + '/test_contour.pxl', 'rb') as f:\n",
        "  test_contour = np.array(pickle.load(f))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrC0wFwRt3z8",
        "colab_type": "text"
      },
      "source": [
        "# **Prepare the data.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9yNFCAUrUid",
        "colab_type": "text"
      },
      "source": [
        "Function definitions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayxCXRSprVvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#separate labels according to the metastasis type\n",
        "def vectorize_labels(labels):\n",
        "  local, distant, death = [], [], []\n",
        "\n",
        "  for metastasis in labels:\n",
        "    local.append(metastasis[0])\n",
        "    distant.append(metastasis[1])\n",
        "    death.append(metastasis[2])\n",
        "\n",
        "  return np.asarray(local).astype('float32'), np.asarray(distant).astype('float32'), np.asarray(death).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSXzmJ0Fui2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalize the data\n",
        "train_x = train_data.astype('float32') / 2000.\n",
        "test_x = test_data.astype('float32') / 2000.\n",
        "\n",
        "#reshape the data\n",
        "train_x = np.reshape(train_x, (len(train_x), 128, 128, 1))\n",
        "test_x  = np.reshape(test_x, (len(test_x), 128, 128, 1))\n",
        "\n",
        "#vectorize the labels\n",
        "train_local, train_distant, train_death = vectorize_labels(train_label)\n",
        "test_local, test_distant, test_death = vectorize_labels(test_label)\n",
        "\n",
        "#display data shape\n",
        "print(\"Input data shape\", train_x.shape)\n",
        "print(\"Input label shape\", train_local.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaBR-zMju3MV",
        "colab_type": "text"
      },
      "source": [
        "# **Build convolutional autoencoder.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs2ro2aprpE7",
        "colab_type": "text"
      },
      "source": [
        "## Encoder and Decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtHsGBj8wzBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_conv2d(layer, filters, stride, name):\n",
        "  layer = Conv2D(filters, kernel_size=(3,3), strides=stride, activation='relu', padding='same', name=('encoder_conv_%s' % name))(layer)\n",
        "  layer = BatchNormalization(name=('encoder_bn_%s' % name))(layer)\n",
        "\n",
        "  return layer\n",
        "\n",
        "def custom_conv2d_transpose(layer, filters, stride, name):\n",
        "  layer = Conv2DTranspose(filters, kernel_size=(3,3), strides=stride, activation='relu', padding='same', name=('decoder_conv_%s' % name))(layer)\n",
        "  layer = BatchNormalization(name=('decoder_bn_%s' % name))(layer)\n",
        "\n",
        "  return layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urTjHzn6w7OZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_encoder_layers(layer, filters_per_layer):\n",
        "  for i, filters in enumerate(filters_per_layer):\n",
        "    layer = custom_conv2d(layer, filters, (1, 1), '1-1_%d' % i)\n",
        "    layer = custom_conv2d(layer, filters, (1, 1), '1-2_%d' % i)\n",
        "    layer = custom_conv2d(layer, filters, (2, 2), '2-1_%d' % i)\n",
        "\n",
        "  return layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_Bzkgi4w91m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_decoder_layers(layer, filters_per_layer):\n",
        "  for i, filters in enumerate(filters_per_layer[::-1]):\n",
        "    layer = custom_conv2d_transpose(layer, filters, (2, 2), '2-1_%d' % i)\n",
        "    layer = custom_conv2d_transpose(layer, filters, (1, 1), '1-2_%d' % i)\n",
        "    layer = custom_conv2d_transpose(layer, filters, (1, 1), '1-1_%d' % i)\n",
        "\n",
        "  output = Conv2D(1, (3, 3), activation='sigmoid', padding='same', name=('decoder_conv_output'))(layer)\n",
        "\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I1DVqasQ0Es",
        "colab_type": "text"
      },
      "source": [
        "## Autoencoder Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIZPNxCkToW4",
        "colab_type": "text"
      },
      "source": [
        "Learning parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7yNjlyIRMmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hyper-parameters\n",
        "epochs_AE = 300\n",
        "epochs_FULL = 200\n",
        "batch_size = 64\n",
        "input_img  = Input(shape=(128, 128, 1))\n",
        "nb_filters = (32, 64, 128)\n",
        "\n",
        "#model layers\n",
        "l = 18"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf837C8_VA4r",
        "colab_type": "text"
      },
      "source": [
        "Build the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ1kf32VxCxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded = build_encoder_layers(input_img, nb_filters)\n",
        "decoded = build_decoder_layers(encoded, nb_filters)\n",
        "\n",
        "ae = Model(input_img, decoded)\n",
        "ae.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
        "ae.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2FRM8BbXWTp",
        "colab_type": "text"
      },
      "source": [
        "Train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4fcegZDXXx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#local   = 0.67\n",
        "#distant = 0.63\n",
        "#death   = 0.64\n",
        "hist = ae.fit(train_x, train_x, \n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs_AE,\n",
        "              verbose=2, \n",
        "              validation_data=(test_x, test_x))\n",
        "\n",
        "#save the model\n",
        "ae.save('/content/drive/My Drive/Bachelor Thesis/autoencoder_300_128_full.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP7yVWLbrE0p",
        "colab_type": "text"
      },
      "source": [
        "Define the fully connected layers that will be stacked up with the encoder function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ7geSNgLRcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#classifier\n",
        "def fc(enco):\n",
        "  flat = Flatten()(enco)\n",
        "  drop = Dropout(0.25)(flat)\n",
        "  den1 = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001))(drop)\n",
        "  drop = Dropout(0.5)(den1)\n",
        "  out  = Dense(1, activation='sigmoid')(drop)\n",
        "\n",
        "  return out\n",
        "\n",
        "#create augmented image generator\n",
        "datagen = ImageDataGenerator(rotation_range=45,\n",
        "                             width_shift_range=0.2,\n",
        "                             height_shift_range=0.2,\n",
        "                             shear_range=0.2,\n",
        "                             zoom_range=0.2,\n",
        "                             horizontal_flip=True,\n",
        "                             fill_mode='nearest')\n",
        "\n",
        "#compute quantities required for featurewise normalization\n",
        "datagen.fit(train_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcJwnXx0YX77",
        "colab_type": "text"
      },
      "source": [
        "Setup up encoder weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81CuSDpBtDaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.load_model('/content/drive/My Drive/Bachelor Thesis/autoencoder_300_128_full.h5')\n",
        "\n",
        "def create_model():\n",
        "  #create the encoder model\n",
        "  encode = build_encoder_layers(input_img, nb_filters)\n",
        "  full_model = Model(input_img, fc(encode))\n",
        "\n",
        "  #set layer weights\n",
        "  for l1, l2 in zip(full_model.layers[:l], model.layers[:l]):\n",
        "    l1.set_weights(l2.get_weights())\n",
        "    l1.trainable = False\n",
        "\n",
        "  #compile the model\n",
        "  full_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "  return full_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa_GX25QYchk",
        "colab_type": "text"
      },
      "source": [
        "Train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1vpwzxBulba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp_model = create_model()\n",
        "tmp_model.fit(datagen.flow(train_x, train_distant, batch_size=32), steps_per_epoch=len(train_x) / 32, epochs=100, verbose=0, validation_data=(test_x, test_distant))\n",
        "pred = tmp_model.predict(test_x)\n",
        "fpr, tpr, _ = roc_curve(test_distant, pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "print(roc_auc)\n",
        "\n",
        "DM_fpr = fpr\n",
        "DM_tpr = tpr\n",
        "DM_auc = roc_auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR722CqECMrg",
        "colab_type": "text"
      },
      "source": [
        "# **Binary Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkaA5pMHdFwd",
        "colab_type": "text"
      },
      "source": [
        "## ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdbiGKUGdIrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(8,6))\n",
        "\n",
        "plt.figure()\n",
        "#plt.plot(LR_fpr, LR_tpr, 'blue', label='Local recurrence, AUC={:.2f}'.format(LR_auc))\n",
        "plt.plot(DM_fpr, DM_tpr, 'green', label='Distant metastasis, AUC={:.2f}'.format(DM_auc))\n",
        "#plt.plot(OS_fpr, OS_tpr, 'red', label='Death, AUC={:.2f}'.format(OS_auc))\n",
        "    \n",
        "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
        "\n",
        "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.xlabel(\"Flase Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
        "plt.legend(prop={'size':13}, loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXozcV7UwG74",
        "colab_type": "text"
      },
      "source": [
        "# **Display Encoding.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "453vH9aDs637",
        "colab_type": "text"
      },
      "source": [
        "Autoencoder image input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2Gh4ff_s8ma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(30, 15))\n",
        "\n",
        "for i in range(32):\n",
        "  sub = fig.add_subplot(4, 8, i+1)\n",
        "  sub.imshow(train_x[i].reshape(160, 160), cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3rNkmND6prj",
        "colab_type": "text"
      },
      "source": [
        "Autoencoder image reconstruction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_2zuMSdwKHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder_rec = tf.keras.models.load_model('/content/drive/My Drive/Bachelor Thesis/autoencoder_300_128_full.h5')\n",
        "\n",
        "decoded_imgs = autoencoder_rec.predict(test_x)\n",
        "\n",
        "# number of scans to display\n",
        "scans = 6\n",
        "\n",
        "plt.figure(figsize=(30, 10))\n",
        "for i in range(scans):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, scans, i + 1)\n",
        "    plt.imshow(test_x[i+2].reshape(128, 128), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, scans, i + scans + 1)\n",
        "    plt.imshow(decoded_imgs[i+2].reshape(128, 128), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izdK4j3A6ubh",
        "colab_type": "text"
      },
      "source": [
        "Autoencoder loss progression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfSxal3K6xgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "\n",
        "epochs = range(epochs_AE)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'g', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}